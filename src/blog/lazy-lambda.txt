[div=bdocs][ul]
[li][url=https://www.fpcomplete.com/user/edwardk/bound]Intro to bound[/url][/li]
[li][url=http://hackage.haskell.org/package/bound]bound on Hackage[/url][/li]
[li][url=code/LazyLambda/LazyLambda.html]Colored Agda[/url][/li]
[/ul][/div]
[pid=chapo]One of the key features of [span=inline-code]bound[/span] is that it
introduces redundancies in the representation of syntaxes in
order to avoid traversing entire subterms just to apply a
weakening. However, equality testing currently quotients out
these redundancies. In this post, I present a lazy equality
test for the untyped lambda calculus with redundancies which does
not perform any of this extra work.[/p]

[p]This works stems out of a bold statement I made and was called
out on by Thomas Braibant during an emacs-driven seminar given in
front of the smart [url=http://gallium.inria.fr/blog/]gallium[/url]
people. The lazy equality test I claimed could be implemented turned
out to be quite a bit more work than I expected & I was not able to
deliver it when asked to. Better late than never.[/p]

[p]Our running example will be the untyped lambda calculus
with its well-known 3 constructors: [span=inline-code]var[/span], [span=inline-code]lam[/span] and
[span=inline-code]app[/span]. We will start by motivating the use of the notion
of [span=inline-code]Scope[/span] when dealing with syntaxes with binding both for
its added safety, genericity and efficiency. We will then move on
to the actual meat of this post: the lazy equality test.[/p]

[h3][url=code/LazyLambda/LazyLambda.html#804]Binding? de Bruijn![/url][/h]

[p]De Bruijn indices are the canonical solution to representing
binding in a language whilst not having to bother with α-conversion.
Here is the inductive definition of the untyped lambda calculus:[/p]

[p=code]data Lam : Set where
  var : (n : Nat)   → Lam
  app : (t u : Lam) → Lam
  lam : (b : Lam)   → Lam[/p]

[p]Unfortunately this ease of use comes at a price: de Bruijn
indices are an inherently untyped approach to context representation
which means that they don't push any sanity check into the type
system. Being the silly programmer I am, I always end up writing
nonsensical expressions. The canonical example may very well be the
definition of substitution
[footnote][url=http://codereview.stackexchange.com/questions/44470/beta-reducer-in-haskell/44518#44518]Weakening[/url]
is also a good candidate for this sort of nonsense given that
one easily forgets to protect bound variables and end up treating
them as if they were free.[/footnote] where one goes under
a binder without even realizing that the former substitution
must be weakened and extended:[/p]

[p=code]subst : Lam → (Nat → Lam) → Lam
subst (var x)   ρ = ρ x
subst (app t u) ρ = app (subst t ρ) (subst u ρ)
[span=bad]subst (lam b)   ρ = lam (subst b ρ)[/span] -- this typechecks...
                                    -- ouch![/p]

[h3][url=code/LazyLambda/LazyLambda.html#2195]Type level de Bruijn indices[/url][/h]

[p]Now, de Bruijn indices are a really great idea when it comes
to handling α-equivalence, capture avoidance, looking variables up
in environments, etc. We would like to retain the general idea behind
them whilst being reminded by the typechecker that some magic needs
to happen after a new variable has been bound.[/p]

[p]Typed alternatives to de Bruijn indices do exist; we can e.g.
think of terms well-scoped by constructions using [span=inline-code]Fin[/span]
or the non-regular datatypes reflecting the indices at the type level
we are going to use:[/p]

[p=code]data Lam (A : Set) : Set where
  var : (a : A)             → Lam A
  app : (t u : Lam A)       → Lam A
  lam : (b : Lam (Maybe A)) → Lam A[/p]

[p][span=inline-code]Lam[/span] quite clearly is a functor hence the existence of
a higher-order function [span=inline-code]map[/span] which loosely corresponds
to the notion of renaming / weakening [footnote]It [i]is[/i]
respectively renaming / weakening provided that the function
passed is well-behaved (resp. bijective / injective).[/footnote].
The [span=inline-code]var[/span] and [span=inline-code]app[/span] cases are unchanged but the type
of the lamdba's body now rejects the erroneous recursive call
described earlier. We are forced to both extend the substitution
with the new bound variable which is unchanged, and weaken the
elements in the rest of the substitution.[/p]

[p=code]subst : (t : Lam A) (ρ : A → Lam B) → Lam B
subst (var a)   ρ = ρ a
subst (app t u) ρ = app (subst t ρ) (subst u ρ)
subst (lam b)   ρ = lam (subst b ρ')
  where ρ' none     = var none
        ρ' (some a) = [span=bad]map some (ρ a)[/span] -- this traverses
                                     -- the whole term[/p]

[p]Unfortunately, this is rather inefficient in that we have to
walk through all the terms in the substitution every time we
pass under a binder.[/p]

[h3][url=code/LazyLambda/LazyLambda.html#5159]Lazy weakenings[/url][/h]

[p]In order to avoid traversing the whole term whenever one just
wants to weaken it, it is quite natural to add some redundancies
in the representation. This can be done by letting the variables
in a subterm be either bound by the nearest binder or [i]whole[/i]
subterms living in the non-extended context (aka weakened subterms).
This naturally translates to the following notions of
[span=inline-code]Scope[/span]:[/p]

[p=code]Scope : (F : Set → Set) (A : Set) → Set
Scope F A = F (Maybe (F A))[/p]

[p]In this case, the definition is simple enough that Agda has no
problem seeing that the [span=inline-code]Scope[/span] transformer preserves
positivity and that [span=inline-code]Lam[/span] is therefore a legal inductive
definition. However in more intricate examples, e.g. when describing
a universe of syntaxes with [span=inline-code]Scope[/span]s, only a tool like
[url=http://www2.tcs.ifi.lmu.de/~abel/miniagda/]MiniAgda[/url]
which allows for positivity annotations will accept the definition
as valid.[/p]

[p=code]data Lam (A : Set) : Set where
  var : (a : A)           → Lam A
  app : (t u : Lam A)     → Lam A
  lam : (b : Scope Lam A) → Lam A[/p]

[h3][url=code/LazyLambda/LazyLambda.html#7263]Equality testing[/url][/h]

[p]All is well when it comes to substitution but what about
equality testing? We have added redundancies which therefore
need to be quotiented out when comparing two terms. The simplest
way to implement such a comparison function is to define a
function [span=inline-code]flatten[/span] which will push the weakenings into the
leaves of the terms thus producing terms in [i]de Bruijn normal
form[/i].[/p]

[p=code]flatten : (t : Scope Lam A) → Lam (Maybe A)[/p]

[h3][url=code/LazyLambda/LazyLambda.html#7932]Lazy equality testing[/url][/h]

[p]Now, we know that we can test terms for equality. But it is not
quite satisfactory yet: we introduced redundancies precisely to avoid
having to perform all of these costly flattenings. But, with a little
bit of work, it is actually possible to perform [i]lazy[/i] equality
testing.[/p]

[h4][url=code/LazyLambda/LazyLambda.html#4498]Context inclusions[/url][/h]

[p]One of the tools we are going to need is a way to describe how
different contexts are related. The terms we are going to compare
will both live in a common context but unfolding them may
very-well bring us to widely different places based on the number
of weakenings respectively encountered on the way down to the
current subterms.[/p]

[p]We introduce this notion of inclusion [footnote]It makes sense as
a notion of inclusion because a proof that [span=inline-code]A ⊆ B[/span] gives rise
to a morphism from [span=inline-code]A[/span] to [span=inline-code]B[/span]. Cf.
[url=code/LazyLambda/LazyLambda.html#4861]the accompanying Agda doc[/url].[/footnote]
whose 2nd constructor ([span=inline-code]↑_[/span]) tags the moment one goes under
a lambda abstraction whilst the 3rd one ([span=inline-code]◂_[/span]) tags the
moment one encounters a weakening. [/p]

[p=code]data _⊆_ : (A B : Set) → Set₁ where
  ■  : A ⊆ A
  ↑_ : A ⊆ B → Maybe (Lam A) ⊆ Maybe (Lam B)
  ◂_ : Maybe (Lam A) ⊆ B → A ⊆ B[/p]

[h4][url=code/LazyLambda/LazyLambda.html#10054]Term comparison[/url][/h]

[p]Now, we are ready to describe the comparison of two terms living
in their respective local contexts [span=inline-code]A[/span] and [span=inline-code]B[/span] both
sharing a common super-context [span=inline-code]T[/span].[/p]

[p=code]data EQ : {T A : Set} (incA : A ⊆ T) (t : Lam A)
          {B : Set}   (incB : B ⊆ T) (u : Lam B)
          → Set₁ where
[/p]
[p]Let's start off with the easy cases: two applications are equal
whenever their functions (resp. arguments) are equal ; and two
lambda abstractions are equal whenever their bodies are equal in
the extended contexts.[/p]
[p=code]  EQapp     : EQ incA t₁ incB t₂ →
              EQ incA u₁ incB u₂ →
              EQ incA (app t₁ u₁) incB (app t₂ u₂)

  EQlam     : EQ (↑ incA) b₁ (↑ incB) b₂ →
              EQ incA (lam b₁) incB (lam b₂)[/p]
[p]When two terms claim to be bound variables, we can compare the
context inclusions to check that they refer to the same lambda
binder. We will describe what this check amounts to in the next
section.[/p]
[p=code]  EQvar     : EQVar incA zero incB zero →
              EQ incA (var none) incB (var none)[/p]
[p]When one of the terms is a weakening of a subterm, we record this
information in the proof of context inclusion and keep on unfolding
further.[/p]
[p=code]  EQvarFre₁ : EQ (◂ incA) v incB u →
              EQ incA (var (some v)) incB u

  EQvarFre₂ : EQ incA t (◂ incB) v →
              EQ incA t incB (var (some v))
[/p]

[p]The careful reader will have noticed that this description is
mostly syntax-directed except for the two last rules which happen
to commute. Turning this specification into a recursive algorithm
will therefore just be a matter of picking an order in which to
check that either [span=inline-code]EQvarFre₁[/span] or [span=inline-code]EQvarFre₂[/span] applies.
Which is good news when you are in the business of actually
deciding equality.[/p]


[h4][url=code/LazyLambda/LazyLambda.html#8474]Variable
comparison[/url][/h]

[p]Variable comparison is always done up to weakenings. We count
the numbers of weakenings encountered thus far respectively in
[span=inline-code]kA[/span] and [span=inline-code]kB[/span] and manage (in/de)crements based on
the tokens we stumble upon.[/p]

[p=code]data EQVar : {TA A : Set} (incA : A ⊆ TA) (kA : Nat)
             {TB B : Set} (incB : B ⊆ TB) (kB : Nat)
             → Set₁ where[/p]
[p]When both context inclusions are synchronized on a lambda
binder (tagged by [span=inline-code]↑_[/span] in the derivations) and no weakening
whatsoever has been applied (both [span=inline-code]kA[/span] and [span=inline-code]kB[/span] are
zero) then we can conclude that the variables are indeed equal.[/p]
[p=code]  EQVarZRO : EQVar (↑ incA) zero (↑ incB) zero
[/p]

[p]When, on the other hand, they both claim to be referring to a
binder which is at least one level up (both [span=inline-code]kA[/span] and
[span=inline-code]kB[/span] are non-zero), one can forget about the binder at hand
and go explore the context inclusions upward.[/p]

[p=code]  EQVarSUC : EQVar incA kA incB kB →
             EQVar (↑ incA) (suc kA) (↑ incB) (suc kB)[/p]
[p]Finally, when we encounter a weakening (marked with a
[span=inline-code]◂_[/span]), we record its presence by incrementing the appropriate
counter and keep comparing the rest of the inclusion proofs.[/p]

[p=code]  EQVarWK₁ : EQVar incA (suc kA) incB kB →
             EQVar (◂ incA) kA incB kB

  EQVarWK₂ : EQVar incA kA incB (suc kB) →
             EQVar incA kA (◂ incB) kB[/p]

[h4][url=code/LazyLambda/LazyLambda.html#12026]Testing equality[/url][/h]

[p]As expected, this specification also is mostly syntax-directed
except for commutative steps. It is thus easy to write an algorithm
checking whether such an equality derivation can be built. And it's
quite a lot simpler to do now that the rules are guiding the
implementation.[/p]
