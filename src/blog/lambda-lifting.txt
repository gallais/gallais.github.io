[div=bdocs][ul]
[li][url=https://gist.github.com/gallais/0b3a50e12542f455c010]Self-contained gist[/url][/li]
[/ul][/div]
[pid=chapo]Lately, I have been working quite a bit with
[url=https://github.com/gallais/type-scope-semantics]an abstract notion
of Semantics[/url] defined as a set of combinators all packed in a
record. Doing so, I have come to enjoy the flexibility provided by
parameterised modules to define operations generically over such a
Semantics. In this blog post, I want to show how this pattern can be
used to tidy up some definitions.[/p]

[h3]Introduction: Scope and lambda lifting[/h]

[p]A module declaration in Agda can be parameterised by a telescope of
arguments. These variables are then made available to the user across
the whole body of the module in a manner reminiscent of Coq's
[url=https://coq.inria.fr/distrib/8.4pl6/refman/Reference-Manual004.html#sec77]Sections[/url].
The most bare-bones example I could come up with is an [tt]Identity[/tt]
module parameterised by [tt]A[/tt], a [tt]Set[/tt], and defining the
identity function for [tt]A[/tt]. This definition is accepted without an
out of scope error being raised because, inside the module, the context
is extended with [tt]A : Set[/tt].[/p]

[p=code]module Identity (A : Set) where

  identity : A → A
  identity = λ x → x
[/p]

[p]Once we leave the module, the type of [tt]identity[/tt] as it is
written down does not make sense anymore because [tt]A[/tt]'s scope
was only extending as far as the module was. The process of taking
such a definition and altering it so that it makes sense even outside
of [tt]Identity[/tt] is called
[url=https://en.wikipedia.org/wiki/Lambda_lifting]lambda-lifting[/url].
It consists in prepending the telescope of arguments the module was
parameterised with

[footnote]
This is only a first approximation. It is
naturally possible to have a slightly more subtle approach and to only
prepend the variables which appear free in the type and body of the
defined symbols together will all the ones they themselves depend on
(and so on recursively). In other words, to only use the smallest,
dependency-closed sub-context containing the variables free in the
defined symbol's type and body.
[/footnote]

to the type and body of the various defined symbols it contains. We can
check that [tt]Identity.identity[/tt]'s type now includes an extra argument:
the type [tt]A[/tt]. Outside the [tt]Identity[/tt] module, it is effectively
the polymorphic identity

[footnote]
[p]Here we write [tt]a ∈ A[/tt] to mean that [tt]a[/tt] has type [tt]A[/tt].
This notion can be defined using a simple indexed family which looks a
lot like propositional equality: because of the way the only constructor
[tt]indeed[/tt] is defined, if [tt]a ∈ A[/tt] is inhabited then [tt]A[/tt]
can only ever be [tt]a[/tt]'s type:[/p]

[p=code]data _∈_ {ℓ : Level} {A : Set ℓ} (a : A) : (B : Set ℓ) → Set where
  indeed : a ∈ A
[/p]
[/footnote]

(the highlighted part is the one generated by the lambda-lifting):[/p]

[p=code]check : Identity.identity ∈ [span=highlight]∀ A →[/span] A → A
check = indeed
[/p]


[h3]A more complex example[/h]

[p]In my experience these parameterised modules are particularly helpful
when you need to make the content of a record, passed as an argument,
available to the type and body of a defined symbol. To keep things simple,
I decided to use one of the most basic constructs in the standard library's
[tt]Algebra[/tt]: a [tt]RawMonoid[/tt]. If you have one such beast, then
you can aggregate values by using the monoid's binary operation and
[url=https://www.youtube.com/watch?v=We90tGh1z3g#t=11m29s]people do
that in [i]real[/i] software[/url].[/p]

[p]This module is called [tt]Reduce[/tt], it is parameterised by a [tt]RawMonoid[/tt]

[footnote]
In the standard library, a [tt]Monoid[/tt] is a [tt]RawMonoid[/tt]
plus some laws. Here we do not care about the proofs that [tt]_∙_[/tt]
is associative and [tt]ε[/tt] a neutral element for it. It goes without
saying that in a general-purpose library, it would be more interesting
to work on a [tt]Monoid[/tt] and prove [tt]aggregate[/tt]'s properties
(e.g. that it is a monoid homomorphism).
[/footnote]

and it implements [tt]aggregate[/tt], a function which collapses a list
of values down to a single one. Here it is crucial for us to be able
to bring the fields of the [tt]RawMonoid mon[/tt] in scope for the
whole definition: [tt]Carrier[/tt], [tt]_∙_[/tt] and [tt]ε[/tt] are
all packed up in that record.[/p]

[p=code]module Reduce {c ℓ : Level} (mon : RawMonoid c ℓ) where

  open RawMonoid mon

  aggregate : List Carrier → Carrier
  aggregate = foldr _∙_ ε[/p]

[p]It would of course be possible to write an equivalent function without
using such a module: it all amounts to lambda-lifting the definition by
hand. However no matter the approach we choose (bringing the same constants
in scope or projecting the values out of the record), the definitions
become far less readable:[/p]

[p=code]aggregate′ : {c ℓ : Level} (mon : RawMonoid c ℓ) →
             let open RawMonoid mon in List Carrier → Carrier
aggregate′ mon = let open RawMonoid mon in foldr _∙_ ε

aggregate′′ : {c ℓ : Level} (mon : RawMonoid c ℓ) →
              List (RawMonoid.Carrier mon) → RawMonoid.Carrier mon
aggregate′′ mon = foldr (RawMonoid._∙_ mon) (RawMonoid.ε mon)
[/p]

[p]We can now use [tt]aggregate[/tt] with an extra argument (the
[tt]RawMonoid[/tt] in question). Assuming we have [tt]ℕ+[/tt] and
[tt]ℕ*[/tt] (respectively the additive and multiplicative monoids over
the natural numbers) and a function [tt][_⋯_][/tt] generating a range
of natural numbers, we can write some test about computations involving
[tt]aggregate[/tt]:[/p]

[p=code]test-aggregate : Reduce.aggregate ℕ+ [ 1 ⋯ 5 ] ≡ 15
               ∧ Reduce.aggregate ℕ* [ 1 ⋯ 5 ] ≡ 120
test-aggregate = refl , refl[/p]

[p]One last thing I like to do in this sort of situation, especially
when defining what could be considered a semantics, is to anticipate
the lambda-lifting and define an infix operator which uses a double
turnstile (⊨) to separate the specific theory used from the
(parametrically defined) computation it acts upon. Here this would mean
adding the following line [b]inside[/b] the module [tt]Reduce[/tt]:[/p]

[p=code]  _⊨reduce_ = aggregate[/p]

[p][tt]_⊨reduce_[/tt] is supposed to take two arguments but, inside
[tt]Reduce[/tt], [tt]aggregate[/tt] only takes one. This weird mismatch
is solved when we leave the module and the [tt]RawMonoid[/tt] argument
is lambda-lifted. We can now write [tt]A ⊨reduce xs[/tt] to mean that we use
the monoid [tt]A[/tt] to give a meaning to the phrase "reduce xs".
The same tests as before hold but I find the type more readable:[/p]

[p=code]test-reduce : ℕ+ ⊨reduce [ 1 ⋯ 5 ] ≡ 15
            ∧ ℕ* ⊨reduce [ 1 ⋯ 5 ] ≡ 120
test-reduce = refl , refl[/p]

